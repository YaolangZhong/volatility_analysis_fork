{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c08c934",
   "metadata": {},
   "source": [
    "This file is used to clean and merge Eora dataset.\n",
    "\n",
    "Eora dataset is well structured. However, we need to reconstruct the data since we define our own country list (to be consistent with country set in CEPII and Tariff). Besides, we also need to extendt the RoW in original Eora to multiple sectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fb38cf",
   "metadata": {},
   "source": [
    "Need to check:\n",
    "\n",
    "- Country list\n",
    "\n",
    "- Sector list\n",
    "\n",
    "- Estimation Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aab6cb8",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12fd0a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2  \n",
    "\n",
    "from Functions import read_files, check_consistency, IO_country_merge_function, IO_sector_merge_function, IO_sector_remove_function, FD_country_merge_function, FD_sector_merge_function, FD_sector_remove_function, VA_country_merge_function, VA_sector_merge_function, VA_sector_remove_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d37448e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/lishuangcen/Dropbox/Tariff_Project\n",
      "Eora BP data folder: 2_Data/Eora26_bp\n"
     ]
    }
   ],
   "source": [
    "# Set working directory\n",
    "wd = os.path.expanduser(\"~/Dropbox/Tariff_Project\")\n",
    "os.chdir(wd)\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# 3. Define data paths and parameters\n",
    "# Path to raw Eora BP data\n",
    "data_path = \"2_Data\"\n",
    "bp_path = os.path.join(data_path, \"Eora26_bp\")\n",
    "\n",
    "# This creates a list of years from 1995 to 2017 (inclusive). Note that the upper bound is exlucded\n",
    "# years = list(range(1995, 2018))  \n",
    "\n",
    "# If we only do with one year\n",
    "# But all the codes in this file can be used to deal with multiple years, since all variables are in dict type\n",
    "years = [2017]\n",
    "\n",
    "# Verify paths\n",
    "print(f\"Eora BP data folder: {bp_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53eb5ee",
   "metadata": {},
   "source": [
    "# Check Consistency and Difine My Country List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "105549ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year  Country_Consistent  Sector_Consistent\n",
      "0  2017                True               True\n",
      "['AFG', 'ALB', 'DZA', 'AND', 'AGO', 'ATG', 'ARG', 'ARM', 'ABW', 'AUS', 'AUT', 'AZE', 'BHS', 'BHR', 'BGD', 'BRB', 'BLR', 'BEL', 'BLZ', 'BEN', 'BMU', 'BTN', 'BOL', 'BIH', 'BWA', 'BRA', 'VGB', 'BRN', 'BGR', 'BFA', 'BDI', 'KHM', 'CMR', 'CAN', 'CPV', 'CYM', 'CAF', 'TCD', 'CHL', 'CHN', 'COL', 'COG', 'CRI', 'HRV', 'CUB', 'CYP', 'CZE', 'CIV', 'PRK', 'COD', 'DNK', 'DJI', 'DOM', 'ECU', 'EGY', 'SLV', 'ERI', 'EST', 'ETH', 'FJI', 'FIN', 'FRA', 'PYF', 'GAB', 'GMB', 'GEO', 'DEU', 'GHA', 'GRC', 'GRL', 'GTM', 'GIN', 'GUY', 'HTI', 'HND', 'HKG', 'HUN', 'ISL', 'IND', 'IDN', 'IRN', 'IRQ', 'IRL', 'ISR', 'ITA', 'JAM', 'JPN', 'JOR', 'KAZ', 'KEN', 'KWT', 'KGZ', 'LAO', 'LVA', 'LBN', 'LSO', 'LBR', 'LBY', 'LIE', 'LTU', 'LUX', 'MAC', 'MDG', 'MWI', 'MYS', 'MDV', 'MLI', 'MLT', 'MRT', 'MUS', 'MEX', 'MCO', 'MNG', 'MNE', 'MAR', 'MOZ', 'MMR', 'NAM', 'NPL', 'NLD', 'ANT', 'NCL', 'NZL', 'NIC', 'NER', 'NGA', 'NOR', 'PSE', 'OMN', 'PAK', 'PAN', 'PNG', 'PRY', 'PER', 'PHL', 'POL', 'PRT', 'QAT', 'KOR', 'MDA', 'ROU', 'RUS', 'RWA', 'WSM', 'SMR', 'STP', 'SAU', 'SEN', 'SRB', 'SYC', 'SLE', 'SGP', 'SVK', 'SVN', 'SOM', 'ZAF', 'SDS', 'ESP', 'LKA', 'SUD', 'SUR', 'SWZ', 'SWE', 'CHE', 'SYR', 'TWN', 'TJK', 'THA', 'MKD', 'TGO', 'TTO', 'TUN', 'TUR', 'TKM', 'USR', 'UGA', 'UKR', 'ARE', 'GBR', 'TZA', 'USA', 'URY', 'UZB', 'VUT', 'VEN', 'VNM', 'YEM', 'ZMB', 'ZWE', 'ROW']\n",
      "Number of countries: 190\n",
      "['Agriculture', 'Fishing', 'Mining and Quarrying', 'Food & Beverages', 'Textiles and Wearing Apparel', 'Wood and Paper', 'Petroleum, Chemical and Non-Metallic Mineral Products', 'Metal Products', 'Electrical and Machinery', 'Transport Equipment', 'Other Manufacturing', 'Recycling', 'Electricity, Gas and Water', 'Construction', 'Maintenance and Repair', 'Wholesale Trade', 'Retail Trade', 'Hotels and Restraurants', 'Transport', 'Post and Telecommunications', 'Finacial Intermediation and Business Activities', 'Public Administration', 'Education, Health and Other Services', 'Private Households', 'Others', 'Re-export & Re-import', 'TOTAL']\n",
      "Number of sectors: 27\n"
     ]
    }
   ],
   "source": [
    "# Check consistency:  we need to make sure if the country list and sector list is the same within the sample years\n",
    "# Import labels: label_T is the country * sector files\n",
    "label_T = read_files(bp_path, years, \"labels_T.txt\")\n",
    "\n",
    "consistency_df, country_list, sector_list = check_consistency(label_T)\n",
    "\n",
    "# Preview consistency results\n",
    "print(consistency_df)\n",
    "\n",
    "# country_list and sector_list contain reference codes\n",
    "print(country_list)\n",
    "print(f\"Number of countries: {len(country_list)}\")\n",
    "print(sector_list)\n",
    "print(f\"Number of sectors: {len(sector_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30db1bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tariff intersection? False\n",
      "Number of selected countries: 36\n"
     ]
    }
   ],
   "source": [
    "# Decide My Country List\n",
    "# You can switch between using tariff intersection or a manual list via the `use_tariff_intersection` flag.\n",
    "\n",
    "# Flag to toggle method\n",
    "# this make easy to choose method 1 or method 2 to define country list; now I use method 2\n",
    "use_tariff_intersection = False \n",
    "\n",
    "if use_tariff_intersection:\n",
    "    # Method 1: derive from tariff data intersection\n",
    "    tariff_df = pd.read_csv(os.path.join(data_path, \"sectoral_tariff_2017.csv\"))\n",
    "    im_countries_tariff = tariff_df['Importer'].unique().tolist()\n",
    "    ex_countries_tariff = tariff_df['Exporter'].unique().tolist()\n",
    "    # Ensure importer and exporter lists match\n",
    "    if set(im_countries_tariff) != set(ex_countries_tariff):\n",
    "        print(\"Warning: Importer and exporter country lists differ.\")\n",
    "    # Intersect with Eora country_list (reference)\n",
    "    my_country_list = [c for c in country_list if c in im_countries_tariff]\n",
    "else:\n",
    "    # Method 2: manual definition\n",
    "    my_country_list = [\n",
    "        \"USA\", \"JPN\", \"DEU\", \"FRA\", \"GBR\", \"ITA\", \"BRA\", \"CHN\", \"ESP\", \"CAN\",\n",
    "        \"KOR\", \"NLD\", \"AUS\", \"IND\", \"RUS\", \"MEX\", \"BEL\", \"SWE\", \"TUR\",\n",
    "        \"AUT\", \"DNK\", \"POL\", \"GRC\", \"FIN\", \"PRT\", \"IRL\", \"CZE\", \"HUN\", \"ROU\",\n",
    "        \"SVK\", \"SVN\", \"TWN\", \"BGR\", \"LTU\", \"EST\", \"VNM\"\n",
    "    ]\n",
    "\n",
    "# Remove \"ROW\" if present\n",
    "my_country_list = [c for c in my_country_list if c != \"ROW\"]\n",
    "\n",
    "# Generate codes mapping relative to country_list\n",
    "code_my_country = [country_list.index(c) + 1 for c in my_country_list if c in country_list]\n",
    "code_row = [i for i in range(1, len(country_list)+1) if i not in code_my_country]\n",
    "\n",
    "# Summary\n",
    "print(f\"Using tariff intersection? {use_tariff_intersection}\")\n",
    "print(f\"Number of selected countries: {len(my_country_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b46935b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "N_old = len(country_list) - 1  # except ROW\n",
    "J_old = len(sector_list) - 1  # except \"TOTAL\" for ROW\n",
    "\n",
    "# ROW has index 190\n",
    "code_row = [code for code in code_row if code != 190]\n",
    "\n",
    "print(N_old)\n",
    "print(J_old)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c53a3c",
   "metadata": {},
   "source": [
    "# Manipulate IO Tables (T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e463ecb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "file_data_T_bp = \"Eora26_XXXX_bp_T.txt\"\n",
    "bp_data_T = read_files(bp_path, years, file_data_T_bp)\n",
    "\n",
    "# Convert DataFrame to NumPy matrix, replacing NaNs with 0\n",
    "bp_matrix_T = {\n",
    "    year: df.fillna(0).values.astype(float)\n",
    "    for year, df in bp_data_T.items()\n",
    "}\n",
    "\n",
    "print(type(bp_matrix_T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cba3c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_country_merged_list = {\n",
    "    year: IO_country_merge_function(\n",
    "        io_matrix=bp_matrix_T[year],\n",
    "        N=N_old,\n",
    "        J=J_old,\n",
    "        code_my_country=code_my_country,\n",
    "        code_row=code_row\n",
    "    ) for year in bp_matrix_T\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da93c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "J_new = J_old\n",
    "N_new = len(my_country_list) + 1  # to include ROW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "735d0616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sector 26 (Re-export and Re-import) corresponds to index 25 (0-based indexing)\n",
    "sector_to_remove = 25\n",
    "\n",
    "T_final = {\n",
    "    year: IO_sector_remove_function(\n",
    "        io_matrix=matrix,\n",
    "        N=N_new,\n",
    "        J=J_new,\n",
    "        sector_to_remove=sector_to_remove\n",
    "    ) \n",
    "    for year, matrix in T_country_merged_list.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d45f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_final = N_new\n",
    "J_final = J_new -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf2eaf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension should be: 925 * 925 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'2017': (925, 925)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the dimensions are correct\n",
    "print(f\"The dimension should be: {N_final * J_final} * {N_final * J_final} \")\n",
    "{year: matrix.shape for year, matrix in T_final.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49501352",
   "metadata": {},
   "source": [
    "# Manipulate Final Demand Tables (FD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70cd0c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Demand matrix shapes:\n",
      "Year 2017: shape = (4915, 1140)\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "\n",
    "file_data_FD_bp = \"Eora26_XXXX_bp_FD.txt\"\n",
    "bp_data_FD = read_files(bp_path, years, file_data_FD_bp)\n",
    "\n",
    "# Convert to matrix and fill missing values\n",
    "bp_matrix_FD = {\n",
    "    year: df.fillna(0).values.astype(float)\n",
    "    for year, df in bp_data_FD.items()\n",
    "}\n",
    "\n",
    "# Check if all matrices have expected 6 final demand accounts (columns)\n",
    "FD_shapes = {year: matrix.shape for year, matrix in bp_matrix_FD.items()}\n",
    "print(\"Final Demand matrix shapes:\")\n",
    "for year, shape in FD_shapes.items():\n",
    "    print(f\"Year {year}: shape = {shape}\")\n",
    "\n",
    "# Final demand accounts count (from Eora documentation)\n",
    "FD_num = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "950c750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FD_country_merged_list = {\n",
    "    year: FD_country_merge_function(\n",
    "        fd_matrix=matrix,\n",
    "        N=N_old,\n",
    "        J=J_old,\n",
    "        FD_num=FD_num,\n",
    "        code_my_country=code_my_country,\n",
    "        code_row=code_row,\n",
    "        index_ROW=190  # or whatever `ROW` was defined as\n",
    "    )\n",
    "    for year, matrix in bp_matrix_FD.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88a1a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "FD_final = {\n",
    "    year: FD_sector_remove_function(\n",
    "        fd_matrix=matrix,\n",
    "        N=N_new,\n",
    "        J=J_new,  \n",
    "        sector_to_remove = 25 \n",
    "    )\n",
    "    for year, matrix in FD_country_merged_list.items()\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb79ed04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension should be: 925 * 222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'2017': (925, 222)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the dimensions are correct\n",
    "print(f\"The dimension should be: {N_final * J_final} * {N_final * FD_num}\")\n",
    "{year: matrix.shape for year, matrix in FD_final.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e8ee82",
   "metadata": {},
   "source": [
    "# Manipulate Value Added Tables (VA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36c6fa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data_VA_bp = \"Eora26_XXXX_bp_VA.txt\"\n",
    "bp_data_VA = read_files(bp_path, years, file_data_VA_bp)\n",
    "\n",
    "bp_matrix_VA = {\n",
    "    year: df.fillna(0).values.astype(float)\n",
    "    for year, df in bp_data_VA.items()\n",
    "}\n",
    "\n",
    "VA_num = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7fedea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "VA_country_merged_list = {\n",
    "    year: VA_country_merge_function(\n",
    "        va_matrix=matrix,\n",
    "        N=N_old,\n",
    "        J=J_old,\n",
    "        VA_num=VA_num,\n",
    "        code_my_country=code_my_country,\n",
    "        code_row=code_row\n",
    "    )\n",
    "    for year, matrix in bp_matrix_VA.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3aa0cc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "VA_final = {\n",
    "    year: VA_sector_remove_function(\n",
    "        va_matrix=matrix,\n",
    "        N=N_new,\n",
    "        J=J_new,\n",
    "        sector_to_remove=25  \n",
    "    )\n",
    "    for year, matrix in VA_country_merged_list.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aab9a88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension should be: 6 * 925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'2017': (6, 925)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the dimensions are correct\n",
    "print(f\"The dimension should be: {VA_num} * {N_final * J_final}\")\n",
    "{year: matrix.shape for year, matrix in VA_final.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610283c5",
   "metadata": {},
   "source": [
    "# Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e047bddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define country list with ROW at the end\n",
    "row_country_list = [c for c in country_list if c not in my_country_list]\n",
    "remaining_country_list = [c for c in country_list if c not in row_country_list]\n",
    "all_country = remaining_country_list + [\"ROW\"]\n",
    "\n",
    "\n",
    "all_sector = sector_list[:-2]\n",
    "\n",
    "\n",
    "# Generate label DataFrame (country-sector pairs)\n",
    "labels = pd.DataFrame({\n",
    "    \"Country\": sum([[c]*len(all_sector) for c in all_country], []),\n",
    "    \"Sector\": all_sector * len(all_country)\n",
    "})\n",
    "\n",
    "# Create save path\n",
    "save_path = \"3_Result/eora_clean/\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# Save label-related CSVs\n",
    "labels.to_csv(os.path.join(save_path, \"labels.csv\"))\n",
    "pd.Series(all_country).to_csv(os.path.join(save_path, \"country_list.csv\"), index=False)\n",
    "pd.Series(all_sector).to_csv(os.path.join(save_path, \"sector_list.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a32b7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    y_str = str(year)\n",
    "    filename_T = os.path.join(save_path, f\"T_final_{y_str}.csv\")\n",
    "    filename_FD = os.path.join(save_path, f\"FD_final_{y_str}.csv\")\n",
    "    filename_VA = os.path.join(save_path, f\"VA_final_{y_str}.csv\")\n",
    "\n",
    "    pd.DataFrame(T_final[y_str]).to_csv(filename_T, index=False)\n",
    "    pd.DataFrame(FD_final[y_str]).to_csv(filename_FD, index=False)\n",
    "    pd.DataFrame(VA_final[y_str]).to_csv(filename_VA, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea4f839",
   "metadata": {},
   "source": [
    "# Check\n",
    "\n",
    "This part is used to create tne original IO talbe with label, to check if the merging work above is correct or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e44e12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IO table with labels\n",
    "year0 = next(iter(bp_matrix_T))        \n",
    "matrix = bp_matrix_T[year0]  \n",
    "labels_df = label_T[year0]\n",
    "\n",
    "labels = labels_df.iloc[:, [0, 3]].astype(str).agg('_'.join, axis=1).tolist()\n",
    "\n",
    "assert matrix.shape[0] == len(labels), \\\n",
    "    f\"number of labels ({len(labels)}) not equal matrix dimensions ({matrix.shape[0]})\"\n",
    "\n",
    "\n",
    "df = pd.DataFrame(matrix,\n",
    "                index=labels,\n",
    "                columns=labels)\n",
    "\n",
    "\n",
    "df.to_csv(os.path.join(wd, \"check/IO_with_labels.csv\"), index=True, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08d0d552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FD table with labels\n",
    "label_FD = read_files(bp_path, years, \"labels_FD.txt\")\n",
    "\n",
    "matrix = bp_matrix_FD[year0]\n",
    "labels_fd_df = label_FD[year0]\n",
    "\n",
    "labels_fd = labels_fd_df.iloc[:, [0, 3]].astype(str).agg('_'.join, axis=1).tolist()\n",
    "\n",
    "df = pd.DataFrame(matrix,\n",
    "                index=labels,\n",
    "                columns=labels_fd)\n",
    "\n",
    "\n",
    "df.to_csv(os.path.join(wd, \"check/FD_with_labels.csv\"), index=True, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0d42209",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded = [c for c in all_country  for _ in range(6)]\n",
    "df_labels = pd.DataFrame({\"country\": expanded})\n",
    "df_labels.to_csv(os.path.join(wd, \"check/fd_labels.csv\"), index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32619feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VA table with labels\n",
    "\n",
    "label_VA = read_files(bp_path, years, \"labels_VA.txt\")\n",
    "\n",
    "matrix = bp_matrix_VA[year0]\n",
    "labels_va_df = label_VA[year0]\n",
    "\n",
    "labels_va = labels_va_df.iloc[:, [1]].astype(str).agg('_'.join, axis=1).tolist()\n",
    "\n",
    "\n",
    "df = pd.DataFrame(matrix,\n",
    "                index=labels_va,\n",
    "                columns=labels)\n",
    "\n",
    "\n",
    "df.to_csv(os.path.join(wd, \"check/VA_with_labels.csv\"), index=True, encoding=\"utf-8\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
