{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import cProfile, pstats, io\n",
    "from models import ModelParams, ModelShocks, ModelSol\n",
    "from optimization import objective_w_hat_reduced\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"output\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# data = np.load(\"real_data.npz\")\n",
    "data = np.load(\"real_data_2017.npz\")\n",
    "N, J = data[\"N\"], data[\"J\"]\n",
    "mp = ModelParams(\n",
    "    N=N,\n",
    "    J=J,\n",
    "    alpha=data[\"alpha\"],\n",
    "    beta=data[\"beta\"],\n",
    "    gamma=data[\"gamma\"],\n",
    "    theta=data[\"theta\"],\n",
    "    pif=data[\"pi_f\"],\n",
    "    pim=data[\"pi_m\"],\n",
    "    tilde_tau=data[\"tilde_tau\"],\n",
    "    Xf=np.ones((N, J)),\n",
    "    Xm=np.ones((N, J)),\n",
    "    w0=data[\"VA\"],\n",
    "    L0=np.ones_like(data[\"VA\"]),\n",
    "    td=data[\"D\"],\n",
    ")\n",
    "\n",
    "bench_shocks = ModelShocks.load_from_npz(os.path.join(out_dir, \"benchmark/shocks.npz\"), mp)\n",
    "\n",
    "\n",
    "GLOBAL_mp = None\n",
    "GLOBAL_bench_sol = None\n",
    "GLOBAL_numeraire_index = None\n",
    "\n",
    "\n",
    "class EarlyStopException(Exception):\n",
    "    \"\"\"Optimization early stop signal.\"\"\"\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "def init_worker(mp, bench_sol, numeraire_index):\n",
    "    \"\"\"Initialize worker processes.\"\"\"\n",
    "    global GLOBAL_mp\n",
    "    global GLOBAL_bench_sol\n",
    "    global GLOBAL_numeraire_index\n",
    "    GLOBAL_mp = mp\n",
    "    GLOBAL_bench_sol = bench_sol\n",
    "    GLOBAL_numeraire_index = numeraire_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_reduced = N - 1\n",
    "# Initial guess for the reduced problem\n",
    "x0_guess = np.ones(dim_reduced)\n",
    "\n",
    "# (B) Example of early stop with callback\n",
    "best_x = [None]\n",
    "res = None\n",
    "\n",
    "iter_count = [0]\n",
    "\n",
    "n = len(x0_guess)\n",
    "eps = 1e-12  # 0に限りなく近い正の値を設定\n",
    "bnds = [(eps, None)] * n  # 下限：eps, 上限：制限なし\n",
    "\n",
    "numeraire_index = 0\n",
    "\n",
    "Xf_init = mp.Xf.copy()\n",
    "Xm_init = mp.Xm.copy()\n",
    "\n",
    "\n",
    "def callback_func(xk):\n",
    "    \"\"\"Callback function to check the objective value and stop the optimization.\"\"\"\n",
    "    iter_count[0] += 1  # Increment the iteration counter\n",
    "    val = objective_w_hat_reduced(\n",
    "        xk, mp, bench_shocks, Xf_init, Xm_init, numeraire_index\n",
    "    )\n",
    "    # Print the current loss value for each iteration\n",
    "    print(f\"Iteration {iter_count[0]}: loss = {val}\")\n",
    "    threshold = 1e-6\n",
    "    if val < threshold:\n",
    "        best_x[0] = xk.copy()\n",
    "        raise EarlyStopException(\n",
    "            f\"Residual {val} < threshold {threshold}. Early stopping.\"\n",
    "        )\n",
    "\n",
    "# try:\n",
    "#     # (C) Optimize w_hat by using Nelder-Mead method\n",
    "#     res = minimize(\n",
    "#         objective_w_hat_reduced,\n",
    "#         x0_guess,\n",
    "#         args=(mp, bench_shocks, Xf_init, Xm_init, numeraire_index),\n",
    "#         # method=\"Nelder-Mead\",\n",
    "#         method=\"L-BFGS-B\",\n",
    "#         bounds=bnds,\n",
    "#         callback=callback_func,\n",
    "#         options={\"maxiter\": 10000, \"disp\": True},\n",
    "#     )\n",
    "# except EarlyStopException as e:\n",
    "#     print(\"Early stop triggered:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: loss = 0.012346351852317361\n",
      "Iteration 2: loss = 0.006001047895900565\n",
      "Iteration 3: loss = 0.005843174136111443\n",
      "Iteration 4: loss = 0.004451119477670087\n",
      "Iteration 5: loss = 0.0035338343563096897\n",
      "Iteration 6: loss = 0.0032484028623443895\n",
      "Iteration 7: loss = 0.002954258071530411\n",
      "Iteration 8: loss = 0.002945698302513719\n",
      "Iteration 9: loss = 0.0029453131398309166\n",
      "Iteration 10: loss = 0.002945293121120793\n",
      "Iteration 11: loss = 0.00294529229266479\n"
     ]
    }
   ],
   "source": [
    "# Create a profiler object\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()  # start profiling\n",
    "\n",
    "# Run the optimization and capture the return value in 'result'\n",
    "result = minimize(\n",
    "    objective_w_hat_reduced,\n",
    "    x0_guess,\n",
    "    args=(mp, bench_shocks, Xf_init, Xm_init, numeraire_index),\n",
    "    method=\"L-BFGS-B\",\n",
    "    bounds=bnds,\n",
    "    callback=callback_func,\n",
    "    options={\"maxiter\": 10000, \"disp\": True},\n",
    ")\n",
    "\n",
    "profiler.disable()  # stop profiling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         23047238 function calls (23047067 primitive calls) in 364.111 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 378 to 20 due to restriction <20>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      3/2    0.000    0.000  364.111  182.055 /opt/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3541(run_code)\n",
      "      3/2    0.000    0.000  364.111  182.055 {built-in method builtins.exec}\n",
      "        1    0.000    0.000  364.110  364.110 /var/folders/q7/lwn2vx9138g3s5z2vnwb01z80000gn/T/ipykernel_31362/3296041888.py:1(<module>)\n",
      "        1    0.000    0.000  364.110  364.110 /opt/miniconda3/lib/python3.12/site-packages/scipy/optimize/_minimize.py:53(minimize)\n",
      "     2376    0.597    0.000  362.056    0.152 /opt/miniconda3/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:16(wrapped)\n",
      "       71    0.000    0.000  361.161    5.087 /opt/miniconda3/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:341(fun_and_grad)\n",
      "     2387    1.524    0.001  360.419    0.151 /Users/yaolangzhong/Dropbox/Carbon_Emission_Analysis_2017/volatility_analysis/optimization.py:77(objective_w_hat_reduced)\n",
      "        1    0.001    0.001  357.134  357.134 /opt/miniconda3/lib/python3.12/site-packages/scipy/optimize/_lbfgsb_py.py:290(_minimize_lbfgsb)\n",
      "       72    0.000    0.000  352.387    4.894 /opt/miniconda3/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:303(_update_grad)\n",
      "       66    0.000    0.000  352.386    5.339 /opt/miniconda3/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:46(wrapped1)\n",
      "       66    0.002    0.000  352.386    5.339 /opt/miniconda3/lib/python3.12/site-packages/scipy/optimize/_numdiff.py:277(approx_derivative)\n",
      "       66    0.016    0.000  352.379    5.339 /opt/miniconda3/lib/python3.12/site-packages/scipy/optimize/_numdiff.py:584(_dense_difference)\n",
      "     2310    0.026    0.000  352.363    0.153 /opt/miniconda3/lib/python3.12/site-packages/scipy/optimize/_numdiff.py:468(fun_wrapped)\n",
      "     2387    2.332    0.001  279.016    0.117 /Users/yaolangzhong/Dropbox/Carbon_Emission_Analysis_2017/volatility_analysis/solvers.py:13(solve_price_and_cost)\n",
      "  1113045  216.064    0.000  263.817    0.000 /Users/yaolangzhong/Dropbox/Carbon_Emission_Analysis_2017/volatility_analysis/equations.py:33(calc_Pu_hat)\n",
      "     2387    8.930    0.004   78.584    0.033 /Users/yaolangzhong/Dropbox/Carbon_Emission_Analysis_2017/volatility_analysis/equations_matrix.py:6(calc_X)\n",
      "  2238025    1.240    0.000   48.867    0.000 /opt/miniconda3/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:69(_wrapreduction)\n",
      "  1124980    0.561    0.000   47.854    0.000 /opt/miniconda3/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:2349(sum)\n",
      "  2238233   47.449    0.000   47.449    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "     2387   37.968    0.016   38.018    0.016 /opt/miniconda3/lib/python3.12/site-packages/numpy/linalg/_linalg.py:320(solve)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = io.StringIO()\n",
    "stats = pstats.Stats(profiler, stream=s).sort_stats('cumtime')\n",
    "stats.print_stats(20)\n",
    "print(s.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the calc_X function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for full method (Fortran order): 0.02467595797497779 seconds\n",
      "Time for block method (Fortran order): 0.010439625009894371 seconds\n",
      "Max difference in Xf: 0.0\n",
      "Max difference in Xm: 328.13300351406866\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from scipy.linalg import block_diag\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Define dummy ModelParams and ModelShocks classes for testing.\n",
    "# In your actual code, you likely already have these defined.\n",
    "# ---------------------------------------------------------------------------\n",
    "class ModelParams:\n",
    "    def __init__(self, N, J):\n",
    "        self.N = N\n",
    "        self.J = J\n",
    "        self.alpha = np.random.rand(N, J)          # (N, J)\n",
    "        self.beta = np.random.rand(N, J)           # (N, J)\n",
    "        self.gamma = np.random.rand(N, J, J)         # (N, J, J)\n",
    "        self.theta = np.random.rand(J) + 1.0         # (J,)\n",
    "        self.pif = np.random.rand(N, N, J)           # (N, N, J)\n",
    "        self.pim = np.random.rand(N, N, J)           # (N, N, J)\n",
    "        self.tilde_tau = np.ones((N, N, J))          # (N, N, J)\n",
    "        self.Xf = np.random.rand(N, J)               # (N, J)\n",
    "        self.Xm = np.random.rand(N, J)               # (N, J)\n",
    "        self.w0 = np.random.rand(N) + 1.0            # (N,)\n",
    "        self.L0 = np.random.rand(N) + 1.0            # (N,)\n",
    "        self.td = np.random.rand(N)                  # (N,)\n",
    "\n",
    "class ModelShocks:\n",
    "    def __init__(self, mp):\n",
    "        self.params = mp\n",
    "        self.lambda_hat = np.exp(np.random.normal(0.0, 0.2, size=(mp.N, mp.J)))  # (N, J)\n",
    "        self.df_hat = np.ones((mp.N, mp.N, mp.J))  # (N, N, J)\n",
    "        self.dm_hat = np.ones((mp.N, mp.N, mp.J))  # (N, N, J)\n",
    "        self.tilde_tau_prime = np.ones((mp.N, mp.N, mp.J))  # (N, N, J)\n",
    "\n",
    "# Define dimensions for testing\n",
    "N, J = 30, 20\n",
    "mp = ModelParams(N, J)\n",
    "shocks = ModelShocks(mp)\n",
    "\n",
    "# Define additional inputs\n",
    "w_hat = np.random.rand(N) + 1.0   # (N,)\n",
    "td_prime = np.random.rand(N)      # (N,)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Functions for calculating A and B (unchanged from your specification)\n",
    "# ---------------------------------------------------------------------------\n",
    "def calc_A(w_hat, td_prime, mp):\n",
    "    # Compute Af = alpha * (w_hat * w0 * L0 + td_prime) with shape (N, J)\n",
    "    Af = mp.alpha * (w_hat * mp.w0 * mp.L0 + td_prime)[:, np.newaxis]\n",
    "    Am = np.zeros_like(Af)  # (N, J)\n",
    "    # Vectorize using default C-order; we later re-vectorize in Fortran order\n",
    "    Af_vec = Af.reshape(-1)\n",
    "    Am_vec = Am.reshape(-1)\n",
    "    A = np.concatenate([Af_vec, Am_vec])  # (2 * N * J,)\n",
    "    return A\n",
    "\n",
    "def calc_B(pif_hat, pim_hat, mp, shocks):\n",
    "    N, J = mp.alpha.shape\n",
    "    # --- Compute Bff ---\n",
    "    factorff = (shocks.tilde_tau_prime - 1) / shocks.tilde_tau_prime  # shape: (N, N, J)\n",
    "    pif_prime = pif_hat * mp.pif  # shape: (N, N, J)\n",
    "    # Sum over the importer dimension (axis=1) for each sector:\n",
    "    U = np.sum(factorff * pif_prime, axis=1)  # shape: (N, J)\n",
    "    V = mp.alpha  # shape: (N, J)\n",
    "    u, v = U.reshape(-1), V.reshape(-1)  # each of shape (N*J,)\n",
    "    Du = np.diag(u)\n",
    "    # For C-order, rows (countries) are contiguous.\n",
    "    # R = kron(I_N, ones(1, J)) sums over columns for each country.\n",
    "    R = np.kron(np.eye(N), np.ones((1, J)))  # shape: (N, N*J)\n",
    "    # P = kron(I_N, ones(J, 1)) replicates each country sum J times.\n",
    "    P = np.kron(np.eye(N), np.ones((J, 1)))   # shape: (N*J, N)\n",
    "    Dv = np.diag(v)\n",
    "    Bff = Dv @ P @ R @ Du  # shape: (N*J, N*J)\n",
    "\n",
    "    # --- Compute Bfm ---\n",
    "    pim_prime = pim_hat * mp.pim  # shape: (N, N, J)\n",
    "    U = np.sum(factorff * pim_prime, axis=1)  # shape: (N, J)\n",
    "    u = U.reshape(-1)\n",
    "    Du = np.diag(u)\n",
    "    Bfm = Dv @ P @ R @ Du  # shape: (N*J, N*J)\n",
    "\n",
    "    # --- Compute Bmf ---\n",
    "    U_temp = pif_prime / shocks.tilde_tau_prime  # shape: (N, N, J)\n",
    "    U_trans = U_temp.transpose(1, 0, 2)  # shape: (N, N, J) with indices (exporter, importer, sector)\n",
    "    V_temp = mp.gamma  # shape: (N, J, J)\n",
    "    # Compute Bmf_tensor with indices (n, s, i, k) = mp.gamma[n,k,s]*U_trans[i,n,k]\n",
    "    Bmf_tensor = np.einsum(\"nks,ink->nsik\", V_temp, U_trans)\n",
    "    Bmf = Bmf_tensor.reshape((N * J, N * J))\n",
    "    \n",
    "    # --- Compute Bmm ---\n",
    "    U_temp = pim_prime / shocks.tilde_tau_prime  # shape: (N, N, J)\n",
    "    U_trans = U_temp.transpose(1, 0, 2)  # shape: (N, N, J)\n",
    "    Bmm_tensor = np.einsum(\"nks,ink->nsik\", V_temp, U_trans)\n",
    "    Bmm = Bmm_tensor.reshape((N * J, N * J))\n",
    "    \n",
    "    # --- Assemble full B ---\n",
    "    B_top = np.hstack((Bff, Bfm))       # shape: (N*J, 2*N*J)\n",
    "    B_bottom = np.hstack((Bmf, Bmm))      # shape: (N*J, 2*N*J)\n",
    "    B = np.vstack((B_top, B_bottom))    # shape: (2*N*J, 2*N*J)\n",
    "    return B\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Full method: Solve the entire system (I - B)x = A, vectorizing in Fortran order.\n",
    "# ---------------------------------------------------------------------------\n",
    "def calc_X_full_F(w_hat, pif_hat, pim_hat, td_prime, mp, shocks):\n",
    "    N, J = mp.alpha.shape\n",
    "    I = np.eye(2 * N * J, dtype=np.float64)\n",
    "    # Re-vectorize A and B in Fortran order.\n",
    "    A_vec = calc_A(w_hat, td_prime, mp).reshape(-1, order='F')\n",
    "    B_vec = calc_B(mp.pif, mp.pim, mp, shocks).reshape((2 * N * J, 2 * N * J), order='F')\n",
    "    X_vec = np.linalg.solve(I - B_vec, A_vec)\n",
    "    Xf_vec = X_vec[:N * J]\n",
    "    Xm_vec = X_vec[N * J:]\n",
    "    Xf = Xf_vec.reshape((N, J), order='F')\n",
    "    Xm = Xm_vec.reshape((N, J), order='F')\n",
    "    return Xf, Xm\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Blockwise method: Solve the system sector-by-sector (in Fortran order)\n",
    "# ---------------------------------------------------------------------------\n",
    "def calc_X_block_F(w_hat, pif_hat, pim_hat, td_prime, mp, shocks):\n",
    "    N, J = mp.alpha.shape\n",
    "    A_vec = calc_A(w_hat, td_prime, mp).reshape(-1, order='F')\n",
    "    B_vec = calc_B(mp.pif, mp.pim, mp, shocks).reshape((2 * N * J, 2 * N * J), order='F')\n",
    "    Xf_solution = np.empty((N, J), dtype=np.float64)\n",
    "    Xm_solution = np.empty((N, J), dtype=np.float64)\n",
    "    \n",
    "    # In Fortran order, for an (N, J) matrix the columns (sectors) are contiguous.\n",
    "    for j in range(J):\n",
    "        # The block for sector j in Xf is contiguous in Fortran order:\n",
    "        start = j * N\n",
    "        end = (j + 1) * N\n",
    "        # For Xf (first N*J entries) the indices for sector j:\n",
    "        indices_f = np.arange(start, end)\n",
    "        # For Xm (next N*J entries) the indices for sector j:\n",
    "        indices_m = np.arange(N * J + start, N * J + end)\n",
    "        sector_indices = np.concatenate([indices_f, indices_m])  # shape: (2N,)\n",
    "        A_sector = A_vec[sector_indices]\n",
    "        B_sector = B_vec[np.ix_(sector_indices, sector_indices)]\n",
    "        I_sector = np.eye(2 * N, dtype=np.float64)\n",
    "        X_sector = np.linalg.solve(I_sector - B_sector, A_sector)\n",
    "        Xf_solution[:, j] = X_sector[:N]\n",
    "        Xm_solution[:, j] = X_sector[N:]\n",
    "    return Xf_solution, Xm_solution\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Test and time both methods.\n",
    "# ---------------------------------------------------------------------------\n",
    "start_full = time.perf_counter()\n",
    "Xf_full, Xm_full = calc_X_full_F(w_hat, mp.pif, mp.pim, td_prime, mp, shocks)\n",
    "end_full = time.perf_counter()\n",
    "time_full = end_full - start_full\n",
    "\n",
    "start_block = time.perf_counter()\n",
    "Xf_block, Xm_block = calc_X_block_F(w_hat, mp.pif, mp.pim, td_prime, mp, shocks)\n",
    "end_block = time.perf_counter()\n",
    "time_block = end_block - start_block\n",
    "\n",
    "print(\"Time for full method (Fortran order):\", time_full, \"seconds\")\n",
    "print(\"Time for block method (Fortran order):\", time_block, \"seconds\")\n",
    "print(\"Max difference in Xf:\", np.max(np.abs(Xf_full - Xf_block)))\n",
    "print(\"Max difference in Xm:\", np.max(np.abs(Xm_full - Xm_block)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
